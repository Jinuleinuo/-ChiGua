第一章
理解了为什么叫西瓜书，因为一直在研究西瓜
大致明白样本、空间、特征
带有不同特征值的样本再加上空集成为数学意义上的空间
人工智能有很长的发展历史，从60年代开始，从那时起，人们就希望机器能够自己学习，走了很多弯路，才到了今天

休息一会儿
50年代的一个小意外，IBM的一个工程师发明了一个跳棋程序，可以通过分析棋局总结出好棋与坏棋，并战胜了职业选手。这件事让人们相信了“计算机可以完成没有事先显式编程的任务”。而这个小意外推动了计算机的发展。
今天我们把这个跳棋程序的算法称为强化学习。

第二章
2.1 经验误差与过拟合
分类错误的样本数占样本总数的比例称为“错误率”
错误率E=a/m
1-a/m称为“精度”(accuracy)，即“精度=1-错误率”
学习能力“过于强大”的学习器会造成过拟合
学习能力不足的学习器会造成欠拟合
过拟合是无法彻底避免的，我们所能做的只是“缓解”，或者说减小其风险
2.2　评估方法
当我们只有一个包含m个样例的数据集D={(x1,y1)，(x2,y2)，...，(xm,ym)} 时，对D进行适当的处理，从中产生出训练集S和测试集T
2.2.1 留出法
将数据集D划分为训练集S、测试集T
S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计
分层采样（stratified sampling）：训练/测试集的划分要尽可能保持数据分布的一致性训练/测试集的划分要尽可能保持数据分布的一致性
一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。例如进行100次随机划分，每次产生一个训练/测试集用于实验评估，100次后就得到100个结果，而留出法返回的则是这100个结果的平均。
测试集小时，评估结果的方差较大；训练集小时，评估结果的偏差较大
一般而言，测试集至少应含30个样例[Mitchell,1997]
两难：若训练集S大，模型可能更接近用D训练出的模型，但由于T小，评估结果可能不够稳定准确；若测试集T大，则训练集S与D差别更大了，被评估的模型与用D训练出的模型相比可能有较大差别，从而降低了评估结果的保真性(fidelity)
没有完美的解决方案，常见做法是将大约2/3～4/5的样本用于训练，剩余样本用于测试
2.2.2 交叉验证法（k倍交叉验证）
通过分层采样，将数据集D划分为k个大小相似的互斥子集。
每次用1个子集作为测试集，其他全部样本作为训练集；重复K次，获得k组训练/测试集，最终返回k个测试结果的均值
交叉验证法评估结果的稳定性和保真性取决于k的取值，称为“k折交叉验证”(k-fold cross validation)
k最常用的取值是10，此时称为10折交叉验证；其他常用的k值有5、20等
将数据集D划分为k个子集存在多种划分方式
为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，例如常见的有“10次10折交叉验证”
留一法（leave-one-out，LOO）：数据集D中包含m个样本，令k=m
留一法比较准确，但是样本量大时计算开销太大
2.2.3 自助法
m个样本，数据集D，采样产生数据集D′：每次随机从D中挑选一个样本，将其拷贝放入D′；将该样本放回初始数据集D中，该样本下次仍有可能被采到；重复m次，得到包含m个样本的数据集D′，这就是自助采样的结果
初始数据集D中约有36.8%的样本未出现在采样数据集D中
自助法在数据集较小、难以有效划分训练/测试集时很有用，对集成学习等方法有很大的好处
自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些
2.2.4 调参与最终模型
算法的参数，亦称”超参数”，数目常在10以内
模型的参数，数目可能很多，例如大型“深度学习”模型甚至有上百亿个参数（书老了，今年很多是千亿级大模型）
调参和算法选择没什么本质区别：对每种参数配置都训练出模型，然后把对应最好模型的参数作为结果
现实中常用的做法，是对每个参数选定一个范围和变化步长，现实中常用的做法，是对每个参数选定一个范围和变化步长
这样的折中后，调参往往仍很困难
参数调得好不好往往对最终模型性能有关键性影响
2.3 性能度量
衡量模型泛化能力的评价标准，这就是性能度量(performance measure)
性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果；这意味着模型的“好坏”是相对的，什么样的模型是好的，不仅取决于算法和数据，还决定于任务需求
回归任务最常用的性能度量是“均方误差”(mean squared error)
2.3.1 错误率与精度
错误率是分类错误的样本数占样本总数的比例
精度则是分类正确的样本数占样本总数的比例
2.3.2　查准率、查全率与F1
查准率亦称“准确率”
查全率亦称“召回率”（覆盖率）
图片: https://uploader.shimo.im/f/f1fj3ZiB67QI95TL.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTg4MjEzNDcsImZpbGVHVUlEIjoiQjFBd2R5YTFSZGY5YW4zbSIsImlhdCI6MTcxODgyMTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjozODE2ODQyMn0.TxAKSIb6Ula-x-BoA5XVjwgIAic8J8lb7VA2K4CSLNQ
查准率P与查全率R分别定义为
图片: https://uploader.shimo.im/f/hHffJ5rN3TW4E4OV.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTg4MjEzNDcsImZpbGVHVUlEIjoiQjFBd2R5YTFSZGY5YW4zbSIsImlhdCI6MTcxODgyMTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjozODE2ODQyMn0.TxAKSIb6Ula-x-BoA5XVjwgIAic8J8lb7VA2K4CSLNQ
查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低  （想了想，理论上应该不是的，可能是在实际应用中往往有这种情况吧）

“PR曲线”或“PR图”
图片: https://uploader.shimo.im/f/KE0aITbexw1wN71o.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTg4MjEzNDcsImZpbGVHVUlEIjoiQjFBd2R5YTFSZGY5YW4zbSIsImlhdCI6MTcxODgyMTA0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjozODE2ODQyMn0.TxAKSIb6Ula-x-BoA5XVjwgIAic8J8lb7VA2K4CSLNQ

（我不太认可这个图，P或R为1时，另一个不可能取0）

若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，例如图2.3中学习器A的性能优于学习器C
如果两个学习器的P-R曲线发生了交叉，一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。但这个值不太容易估算。
“平衡点”（Break-Even Point，简称BEP）就是这样一个度量，它是“查准率=查全率”时的取值，例如图2.3中学习器C的BEP是0.64，而基于BEP的比较，可认为学习器A优于B。
BEP还是过于简化了些，更常用的是F1度量
F1是基于查准率与查全率的调和平均(harmonicmean)定义的：在一些应用中，对查准率和查全率的重视程度有所不同。例如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要
F1度量的一般形式――Fβ，能让我们表达出对查准率/查全率的不同偏好：β=1时退化为标准的F1；β＞1时查全率有更大影响；β＜1时查准率有更大影响
们有多个二分类混淆矩阵：一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，再计算平均值，这样就得到“宏查准率”(macro-P)、“宏查全率”(macro-R)，以及相应的“宏F1”(macro-F1)
还可先将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、FN的平均值，分别记为，再基于这些平均值计算出“微查准率”(micro-P)、“微查全率”(micro-R)和“微F1”(micro-F1)
